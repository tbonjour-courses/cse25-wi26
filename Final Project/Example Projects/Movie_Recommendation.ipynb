{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System with MovieLens\n",
    "\n",
    "**Problem Statement:** Recommender systems predict a user's preference for items they haven't seen yet. In this project, we build a movie recommendation engine using the MovieLens dataset, exploring Collaborative Filtering, Content-Based Filtering, and Matrix Factorization (SVD).\n",
    "\n",
    "The following code is provided to help you get started. For neural networks approaches, we recommend using a GPU to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages if needed\n",
    "# !pip install scikit-surprise pandas matplotlib seaborn\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Dependencies loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the MovieLens Dataset\n",
    "\n",
    "We use the **MovieLens 100k** dataset.\n",
    "\n",
    "The following code will create a data folder with the MovieLens dataset inside. You only need to run the cell block once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/movielens'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# MovieLens 100K (small, good for development)\n",
    "ML_100K_URL = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "dataset_name = 'ml-latest-small'\n",
    "\n",
    "if not os.path.exists(os.path.join(DATA_DIR, dataset_name)):\n",
    "    print(f\"Downloading MovieLens ({dataset_name})...\")\n",
    "    !wget -q {ML_100K_URL} -O {DATA_DIR}/movielens.zip\n",
    "    !unzip -q {DATA_DIR}/movielens.zip -d {DATA_DIR}\n",
    "    !rm {DATA_DIR}/movielens.zip\n",
    "    print(\"Download complete!\")\n",
    "else:\n",
    "    print(\"Dataset already exists.\")\n",
    "\n",
    "dataset_path = os.path.join(DATA_DIR, dataset_name)\n",
    "print(f\"\\nDataset files: {os.listdir(dataset_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "ratings_df = pd.read_csv(os.path.join(dataset_path, 'ratings.csv'))\n",
    "movies_df = pd.read_csv(os.path.join(dataset_path, 'movies.csv'))\n",
    "tags_df = pd.read_csv(os.path.join(dataset_path, 'tags.csv'))\n",
    "\n",
    "print(\"=== Ratings ===\")\n",
    "print(f\"Shape: {ratings_df.shape}\")\n",
    "print(ratings_df.head())\n",
    "print(f\"\\n=== Movies ===\")\n",
    "print(f\"Shape: {movies_df.shape}\")\n",
    "print(movies_df.head())\n",
    "print(f\"\\n=== Tags ===\")\n",
    "print(f\"Shape: {tags_df.shape}\")\n",
    "print(tags_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "n_users = ratings_df['userId'].nunique()\n",
    "n_movies = ratings_df['movieId'].nunique()\n",
    "n_ratings = len(ratings_df)\n",
    "sparsity = 1 - (n_ratings / (n_users * n_movies))\n",
    "\n",
    "print(f\"Number of users: {n_users:,}\")\n",
    "print(f\"Number of movies: {n_movies:,}\")\n",
    "print(f\"Number of ratings: {n_ratings:,}\")\n",
    "print(f\"Average ratings per user: {n_ratings / n_users:.1f}\")\n",
    "print(f\"Average ratings per movie: {n_ratings / n_movies:.1f}\")\n",
    "print(f\"Matrix sparsity: {sparsity:.4%}\")\n",
    "print(f\"\\nRating distribution:\")\n",
    "print(ratings_df['rating'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rating distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Rating value distribution\n",
    "ratings_df['rating'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Rating Value Distribution')\n",
    "axes[0].set_xlabel('Rating')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Ratings per user\n",
    "user_counts = ratings_df.groupby('userId').size()\n",
    "axes[1].hist(user_counts, bins=50, color='coral', edgecolor='black')\n",
    "axes[1].set_title('Ratings per User')\n",
    "axes[1].set_xlabel('Number of Ratings')\n",
    "axes[1].set_ylabel('Number of Users')\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "# Ratings per movie\n",
    "movie_counts = ratings_df.groupby('movieId').size()\n",
    "axes[2].hist(movie_counts, bins=50, color='mediumseagreen', edgecolor='black')\n",
    "axes[2].set_title('Ratings per Movie')\n",
    "axes[2].set_xlabel('Number of Ratings')\n",
    "axes[2].set_ylabel('Number of Movies')\n",
    "axes[2].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most popular movies\n",
    "movie_stats = ratings_df.groupby('movieId').agg(\n",
    "    avg_rating=('rating', 'mean'),\n",
    "    num_ratings=('rating', 'count')\n",
    ").reset_index()\n",
    "\n",
    "movie_stats = movie_stats.merge(movies_df[['movieId', 'title', 'genres']], on='movieId')\n",
    "\n",
    "# Top 10 most rated movies\n",
    "print(\"Top 10 Most Rated Movies:\")\n",
    "top_movies = movie_stats.nlargest(10, 'num_ratings')[['title', 'num_ratings', 'avg_rating', 'genres']]\n",
    "print(top_movies.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parse Genres (for Content-Based Filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse genres into a multi-hot encoded DataFrame\n",
    "all_genres = set()\n",
    "for genres_str in movies_df['genres']:\n",
    "    if genres_str != '(no genres listed)':\n",
    "        all_genres.update(genres_str.split('|'))\n",
    "\n",
    "all_genres = sorted(all_genres)\n",
    "print(f\"All genres ({len(all_genres)}): {all_genres}\")\n",
    "\n",
    "# Create genre feature matrix\n",
    "genre_matrix = pd.DataFrame(0, index=movies_df['movieId'], columns=all_genres)\n",
    "for _, row in movies_df.iterrows():\n",
    "    if row['genres'] != '(no genres listed)':\n",
    "        for genre in row['genres'].split('|'):\n",
    "            genre_matrix.loc[row['movieId'], genre] = 1\n",
    "\n",
    "print(f\"\\nGenre feature matrix shape: {genre_matrix.shape}\")\n",
    "print(genre_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split ratings into train and test sets\n",
    "# Strategy: For each user, hold out 20% of their ratings for testing\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for user_id, user_ratings in ratings_df.groupby('userId'):\n",
    "    user_train, user_test = train_test_split(\n",
    "        user_ratings, test_size=0.2, random_state=42\n",
    "    )\n",
    "    train_data.append(user_train)\n",
    "    test_data.append(user_test)\n",
    "\n",
    "train_df = pd.concat(train_data).reset_index(drop=True)\n",
    "test_df = pd.concat(test_data).reset_index(drop=True)\n",
    "\n",
    "print(f\"Training ratings: {len(train_df):,}\")\n",
    "print(f\"Test ratings: {len(test_df):,}\")\n",
    "print(f\"Train users: {train_df['userId'].nunique()}, Test users: {test_df['userId'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
