{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7261f0",
   "metadata": {},
   "source": [
    "# CSE 25 – Introduction to Artificial Intelligence\n",
    "## Worksheet 9: Backpropagation and Efficient Learning\n",
    "\n",
    "**Context (from last class):**  \n",
    "Previously, we learned how to use loss functions and gradients to train linear models, and saw how finite differences can estimate gradients.\n",
    "\n",
    "In this worksheet, we will:\n",
    "- Understand why finite-difference gradient computation is slow for large models\n",
    "- Learn the intuition behind **backpropagation** and the chain rule\n",
    "- Implement efficient gradient computation for a simple linear model using backpropagation\n",
    "- Compare backpropagation gradients to finite-difference gradients\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Explain why backpropagation is more efficient than finite differences\n",
    "- Apply the chain rule to compute gradients in a computation graph\n",
    "- Implement backpropagation for a sigmoid + binary cross-entropy model\n",
    "- Use gradients to update model parameters and reduce loss\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "Create a copy of this notebook and complete it during class.  \n",
    "Work through the cells below **in order**.\n",
    "\n",
    "You may discuss with your neighbors, but make sure you understand  \n",
    "what each step is doing and why.\n",
    "\n",
    "**Submission**\n",
    "\n",
    "When finished, download the notebook as a PDF and upload it to Gradescope under  \n",
    "`In-Class – Week 6 Tuesday`.\n",
    "\n",
    "To download as a PDF on DataHub:  \n",
    "`File -> Save and Export Notebook As -> PDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2f22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Load the toy data again for the next section\n",
    "X_toy = [\n",
    "    [1.5, 4],\n",
    "    [1, 2],\n",
    "    [2, 1],\n",
    "    [3, 5],\n",
    "    [4, 2],\n",
    "    [0, 0],\n",
    "    [1.5, -0.5]\n",
    "]\n",
    "y_toy = [1, 1, 0, 1, 0, 0, 0]\n",
    "\n",
    "def stable_sigmoid(z):\n",
    "    \"\"\"\n",
    "    This implementation avoids overflow issues by handling large positive and negative values of z separately.\n",
    "\n",
    "    z: a numeric value.\n",
    "\n",
    "    if z >= 0: use the 'standard' formula: 1/(1 + exp(-z))\n",
    "    if z < 0: use the alternative formula to avoid overflow: exp(z) / (1 + exp(z))\n",
    "    \"\"\"\n",
    "    if z >= 0:\n",
    "        return 1 / (1 + math.exp(-z))\n",
    "    else:\n",
    "        ez = math.exp(z)\n",
    "        return ez / (1 + ez)\n",
    "\n",
    "\n",
    "def stable_binary_cross_entropy(p, y):\n",
    "    \"\"\"\n",
    "    Clips p to avoid (math) issues, then computes binary cross-entropy loss.\n",
    "    \n",
    "    p: model confidence (between 0 and 1)\n",
    "    y: true label (0 or 1)\n",
    "    \"\"\"\n",
    "    eps = 1e-8\n",
    "\n",
    "    if p < eps:\n",
    "        p = eps\n",
    "    if p > 1 - eps:\n",
    "        p = 1 - eps\n",
    "\n",
    "    return -(y * math.log(p) + (1 - y) * math.log(1 - p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da61a82a",
   "metadata": {},
   "source": [
    "## Reducing the loss\n",
    "\n",
    "Earlier in the course, we reduced error by asking:\n",
    "\n",
    "- If we change a parameter slightly, how does the error change?\n",
    "- In which direction should we move the parameter to reduce error?\n",
    "- How sensitive is the error to that parameter?\n",
    "\n",
    "We answered these questions by treating error as a function of the parameters and using **gradients** to understand how changes in the parameters affect the error.\n",
    "\n",
    "[SIDE QUEST](https://docs.google.com/presentation/d/1g1uaurl-GckLb47FskBPzgtsrQJPiAQUhdVML_eOI_8/edit?usp=sharing): Play the slideshow and watch the videos to get some intuition aobut gradients. I have time marked them in the slides, but please feel free to watch the full video.\n",
    "\n",
    "Here, we use the same idea, but with a more precise quantity called a **loss**.\n",
    "\n",
    "The goal is the same:\n",
    "understand how the loss changes with respect to the parameters so that we can update $w$ and $b$ to reduce it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7ca9a4",
   "metadata": {},
   "source": [
    "Our model has three parameters:\n",
    "- $w_1$: weight for feature $x_1$\n",
    "- $w_2$: weight for feature $x_2$\n",
    "- $b$: bias\n",
    "\n",
    "Computation Graph: \n",
    "\n",
    "$x \\xrightarrow{\\,w,b\\,} z \\xrightarrow{\\,\\sigma(.)\\,} p \\xrightarrow{\\,y\\,} L$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa46a2",
   "metadata": {},
   "source": [
    "#### Indexing Convention\n",
    "\n",
    "We will use **two different indices** to distinguish between the feature index and the example index: \n",
    "\n",
    "- **Feature index**: $i = 1, \\dots, n$  \n",
    "  Refers to *which input feature* ($x_1, x_2, \\dots$).\n",
    "\n",
    "- **Example index**: $j = 1, \\dots, N$  \n",
    "  Refers to *which training example* in the dataset.\n",
    "\n",
    "We will write it as:\n",
    "\n",
    "$$\n",
    "x_i^{(j)} \\quad \\text{= feature } i \\text{ of training example } j\n",
    "$$\n",
    "\n",
    "In Python, indexing starts at **0**, so this corresponds to:\n",
    "\n",
    "$$\n",
    "x_i^{(j)} \\;\\longleftrightarrow\\; \\texttt{X[j-1][i-1]}\n",
    "$$\n",
    "\n",
    "In practice, when we loop over the dataset in code, we usually let `j` already range from `0` to `N-1`.  \n",
    "In that case, `X[j]` corresponds to example $j+1$, and we only need to remember that feature indices are also shifted by one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The forward pass to get the confidence values\n",
    "def forward(X, w1, w2, b):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    X: list of data points, where each point is a list of 2 features [x1, x2]\n",
    "    w1, w2: weights for the two features\n",
    "    b: bias term\n",
    "\n",
    "    Output: A list of p (confidence values between 0 and 1) for each data point\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty list to store confidence values\n",
    "    p_list = []\n",
    "\n",
    "    # Iterate through each data point in X\n",
    "    for j in range(len(X)):\n",
    "        x1 = X[j][0]\n",
    "        x2 = X[j][1]\n",
    "        \n",
    "        # Calculate the linear score z = w1*x1 + w2*x2 + b\n",
    "        z = w1 * x1 + w2 * x2 + b\n",
    "        \n",
    "        # Use the score to get the sigmoid confidence\n",
    "        p = stable_sigmoid(z)\n",
    "\n",
    "        # Append the confidence value to the list\n",
    "        p_list.append(p)\n",
    "        \n",
    "    return p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Loss Function\n",
    "def get_avg_binary_cross_entropy(p_list, y):\n",
    "    \"\"\"\n",
    "    \n",
    "    p_list: list of predicted confidence values (between 0 and 1)\n",
    "    y: list of true labels (0 or 1)\n",
    "\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    for j in range(len(p_list)):\n",
    "        p = p_list[j]\n",
    "        y_true = y[j]\n",
    "        \n",
    "        # Safety: Clip p to avoid log(0) error\n",
    "        loss_j = stable_binary_cross_entropy(p, y_true)\n",
    "        total_loss += loss_j\n",
    "        \n",
    "    return total_loss / len(p_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e5b09",
   "metadata": {},
   "source": [
    "### Calculating the Gradient with Respect to Multiple Parameters\n",
    "\n",
    "When our model has more than one input feature, such as\n",
    "$$\n",
    "y = w_1 x_1 + w_2 x_2 + b,\n",
    "$$\n",
    "the loss depends on all the parameters: $w_1$, $w_2$, and $b$. In general, models can have many weights ($w_1, w_2, \\dots, w_n$) and a bias $b$.\n",
    "\n",
    "The loss $\\mathcal{L}(p, y)$ measures how well the model's prediction $p$ matches the true label $y$ for a single data point. We cannot change $y$, so we focus on how changes in the prediction $p$ affect the loss.\n",
    "\n",
    "Since $p$ depends on $z$, which in turn depends on the parameters of our model, the **dataset-level loss** becomes a function of the model parameters:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(w_1, w_2, b)\n",
    "= \\frac{1}{N} \\sum_{j=1}^N \\mathcal{L}\\!\\left(p^{(j)}, y^{(j)}\\right),\n",
    "$$\n",
    "\n",
    "where\n",
    "$$\n",
    "p^{(j)} = \\sigma\\!\\left(z^{(j)}\\right),\n",
    "\\qquad\n",
    "z^{(j)} = w_1 x_1^{(j)} + w_2 x_2^{(j)} + b.\n",
    "$$\n",
    "\n",
    "This is the **average loss over all $N$ training examples**. When we change a parameter (for example, $w_1$), every prediction $p^{(j)}$ may change. As a result, the loss for each data point may change, and the gradient captures the effect of that parameter on the **average loss across the dataset**. This is why, during optimization, we treat the loss as a function of the model parameters.\n",
    "\n",
    "To optimize these parameters, we compute the **partial derivatives** of the average loss with respect to each parameter:\n",
    "\n",
    "- $\\frac{\\partial \\mathcal{L}}{\\partial w_1}$: how the average loss changes as $w_1$ changes, holding the other parameters fixed.\n",
    "- $\\frac{\\partial \\mathcal{L}}{\\partial w_2}$: how the average loss changes as $w_2$ changes, holding the other parameters fixed.\n",
    "- $\\frac{\\partial \\mathcal{L}}{\\partial b}$: how the average loss changes as $b$ changes.\n",
    "\n",
    "One way to approximate these derivatives is the **finite difference method**, which measures how the average dataset loss changes when we slightly nudge one parameter:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_1}\n",
    "\\approx\n",
    "\\frac{\\mathcal{L}(w_1+\\epsilon, w_2, b) - \\mathcal{L}(w_1, w_2, b)}{\\epsilon}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_2}\n",
    "\\approx\n",
    "\\frac{\\mathcal{L}(w_1, w_2+\\epsilon, b) - \\mathcal{L}(w_1, w_2, b)}{\\epsilon}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b}\n",
    "\\approx\n",
    "\\frac{\\mathcal{L}(w_1, w_2, b+\\epsilon) - \\mathcal{L}(w_1, w_2, b)}{\\epsilon}\n",
    "$$\n",
    "\n",
    "Here, $\\epsilon$ is a small number. This idea works for any number of parameters: we nudge one parameter at a time and observe how the **average loss over the dataset** changes. In practice, backpropagation computes these gradients efficiently without rerunning the model separately for each parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf0b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gradient calculation using the finite difference method\n",
    "# To see how $(w,b)$ affect $L$, we nudge one parameter at a time and look at how that affects the loss.\n",
    "\n",
    "def get_gradients(X, y, w1, w2, b):\n",
    "    eps = 0.0001\n",
    "    \n",
    "    # STEP 0: Baseline - Where are we now?\n",
    "    # We must Run Forward -> Then Calculate Loss\n",
    "    base_conf = forward(X, w1, w2, b)\n",
    "    base_loss  = get_avg_binary_cross_entropy(base_conf, y)\n",
    "    \n",
    "    # STEP 1: Get gradient for w1\n",
    "    # Nudge w1 -> Re-run Forward -> Re-calculate Loss\n",
    "    w1_conf = forward(X, w1 + eps, w2, b)\n",
    "    w1_loss  = get_avg_binary_cross_entropy(w1_conf, y)\n",
    "    grad_w1  = (w1_loss - base_loss) / eps\n",
    "    \n",
    "    # STEP 2: Get gradient for w2\n",
    "    # Nudge w2 -> Re-run Forward -> Re-calculate Loss\n",
    "    w2_conf = forward(X, w1, w2 + eps, b)\n",
    "    w2_loss  = get_avg_binary_cross_entropy(w2_conf, y)\n",
    "    grad_w2  = (w2_loss - base_loss) / eps\n",
    "    \n",
    "    # STEP 3: Get gradient for bias\n",
    "    # Nudge b -> Re-run Forward -> Re-calculate Loss\n",
    "    b_conf = forward(X, w1, w2, b + eps)\n",
    "    b_loss  = get_avg_binary_cross_entropy(b_conf, y)\n",
    "    grad_b  = (b_loss - base_loss) / eps\n",
    "     \n",
    "    return grad_w1, grad_w2, grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Training Loop\n",
    "\n",
    "# Initialize Parameters\n",
    "w1 = 0.0\n",
    "w2 = 0.0\n",
    "b  = 0.0\n",
    "\n",
    "# Initialize hyperparameters\n",
    "learning_rate = 0.1\n",
    "epochs = 500\n",
    "\n",
    "print(f\"Initial Loss: {get_avg_binary_cross_entropy(forward(X_toy, w1, w2, b), y_toy):.4f}\")\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # 1. Calculate Gradients (This runs the model 4 times!)\n",
    "    dw1, dw2, db = get_gradients(X_toy, y_toy, w1, w2, b)\n",
    "    \n",
    "    # 2. Update Weights\n",
    "    w1 = w1 - learning_rate * dw1\n",
    "    w2 = w2 - learning_rate * dw2\n",
    "    b  = b  - learning_rate * db\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        # Check progress\n",
    "        curr_preds = forward(X_toy, w1, w2, b)\n",
    "        curr_loss = get_avg_binary_cross_entropy(curr_preds, y_toy)\n",
    "        print(f\"Iter {i}: w1={w1:.2f}, w2={w2:.2f}, b={b:.2f} | Loss={curr_loss:.4f}\")\n",
    "\n",
    "print(\"\\nFinal Result:\")\n",
    "print(\"Final loss:\", curr_loss)\n",
    "\n",
    "print(f\"w1: {w1:.4f}, w2: {w2:.4f}, b: {b:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0479604",
   "metadata": {},
   "source": [
    "We just trained our model by repeating the follwing steps:\n",
    "\n",
    "- Running the model forward to get the confidence values $p$\n",
    "- Computing the loss using $p$ and $y$\n",
    "- Nudging one parameter at a time to see how the loss changes\n",
    "- Updating the parameters using those estimates\n",
    "\n",
    "\n",
    "**Q. This works - but it is slow, not optimal. Why?**\n",
    "\n",
    "*Hint:*  Look closely at `get_gradients(X, y, w1, w2, b)`. How many times does the model run forward and recompute the loss during **one training step**?\n",
    "\n",
    "\n",
    "`YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c49d6",
   "metadata": {},
   "source": [
    "<!-- When using the finite difference method in the training loop above, we must run the model forward and recompute the loss separately for each parameter (once for the baseline, and once for each parameter nudge). For a model with $k$ parameters, this means $k+1$ forward passes per training step. As the number of parameters grows (for example, in deep neural networks with thousands or millions of weights), this approach becomes extremely slow and computationally expensive. This inefficiency is why we need a better method, **backpropagation**, which computes all gradients in a single backward pass, regardless of the number of parameters. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2fbd7",
   "metadata": {},
   "source": [
    "### Backpropagation Idea\n",
    "\n",
    "Each step depends only on the one before it:\n",
    "\n",
    "- The loss $L$ depends on $p$ and $y$ (fixed)\n",
    "- The confidence $p$ depends on $z$\n",
    "- The score $z$ depends on $x$ (fixed), $w$ and $b$\n",
    "\n",
    "So instead of changing one parameter at a time and rerunning everything, we can:\n",
    "\n",
    "1. Start at the loss\n",
    "2. Measure how sensitive the loss is to its input\n",
    "3. Pass that sensitivity backward through the computation\n",
    "\n",
    "This is called **backpropagation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4516a09",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "x \\;\\xrightarrow{w,b}\\; z \\;\\xrightarrow{\\sigma}\\; p \\;\\xrightarrow{y}\\; L\n",
    "$$\n",
    "\n",
    "For the computation graph above, backpropagation answers the following questions:\n",
    "\n",
    "1. If the value of $p$ changes slightly, how much does the loss $L$ change? $\\big(\\frac{\\partial L}{\\partial p}\\big)$\n",
    "2. If the score $z$ changes slightly, how much does the prediction $p$ change? $\\big(\\frac{\\partial p}{\\partial z}\\big)$\n",
    "3. If a parameter ($w$ or $b$) changes slightly, how much does the score $z$ change? $\\big(\\frac{\\partial z}{\\partial w_i}, \\frac{\\partial z}{\\partial b}\\big)$\n",
    "\n",
    "Once we know these **local effects**, we multiply them together.\n",
    "\n",
    "This is the **chain rule**, applied to a computation graph.\n",
    "\n",
    "For any parameter $w_i$, the chain rule gives:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_i}=\n",
    "\\frac{\\partial L}{\\partial p}\n",
    "\\cdot\n",
    "\\frac{\\partial p}{\\partial z}\n",
    "\\cdot\n",
    "\\frac{\\partial z}{\\partial w_i}\n",
    "$$\n",
    "\n",
    "Similarly, for the bias:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b}=\n",
    "\\frac{\\partial L}{\\partial p}\n",
    "\\cdot\n",
    "\\frac{\\partial p}{\\partial z}\n",
    "\\cdot\n",
    "\\frac{\\partial z}{\\partial b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5e447-9445-4b1b-8702-cdb44afea75b",
   "metadata": {},
   "source": [
    "#### Gradients with respect to the score\n",
    "\n",
    "For **one example** $(x, y)$, the gradient of the loss with respect to the score $z$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z} = \\frac{\\partial L}{\\partial p}\n",
    "\\cdot\n",
    "\\frac{\\partial p}{\\partial z}\n",
    "\\cdot = p - y\n",
    "$$\n",
    "\n",
    "You are **not expected** to derive this result in this course. We will use it directly.\n",
    "But if you're interested in learning how we get this - you can see it [here](https://drive.google.com/file/d/1XSSyNVk8HMhs4gKi4odK_hX7BBldkYzb/view?usp=sharing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317d490",
   "metadata": {},
   "source": [
    "#### Understanding the signal `p - y`\n",
    "\n",
    "Recall that gradient descent updates parameters by moving in the **opposite**\n",
    "direction of the gradient.\n",
    "\n",
    "1. If $y = 1$ and $p = 0.8$:\n",
    "   - Is the gradient positive or negative?\n",
    "   - Will the update push the score $z$ **up** or **down**?\n",
    "\n",
    "   `YOUR ANSWER HERE`\n",
    "\n",
    "2. If $y = 1$ and $p = 0.2$:\n",
    "   - Is gradient positive or negative?\n",
    "   - Will the update push the score $z$ **up** or **down**?\n",
    "\n",
    "   `YOUR ANSWER HERE`\n",
    "\n",
    "3. If $y = 0$ and $p = 0.8$:\n",
    "   - Is gradient positive or negative?\n",
    "   - Will the update push the score $z$ **up** or **down**?\n",
    "\n",
    "   `YOUR ANSWER HERE`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046452e9",
   "metadata": {},
   "source": [
    "#### Gradients with respect to the parameters\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial w_i} = x_i,\n",
    "\\qquad\n",
    "\\frac{\\partial z}{\\partial b} = 1\n",
    "$$\n",
    "\n",
    "Using the chain rule, the gradients for **one example** are:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_i} =\n",
    "\\frac{\\partial L}{\\partial p}\n",
    "\\cdot\n",
    "\\frac{\\partial p}{\\partial z}\n",
    "\\cdot\n",
    "\\frac{\\partial z}{\\partial w_i}\n",
    "= (p - y)\\,x_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b}=\n",
    "\\frac{\\partial L}{\\partial p}\n",
    "\\cdot\n",
    "\\frac{\\partial p}{\\partial z}\n",
    "\\cdot\n",
    "\\frac{\\partial z}{\\partial b} = p - y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ba74f",
   "metadata": {},
   "source": [
    "- If the model predicts **too high** ($p > y$), the gradient is positive -> decrease the score next time.\n",
    "- If the model predicts **too low** ($p < y$), the gradient is negative -> increase the score next time.\n",
    "- If the prediction is correct ($p \\approx y$), the gradient is near zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525957e3",
   "metadata": {},
   "source": [
    "### Exercise: Implement Backpropagation Gradients\n",
    "\n",
    "Fill in the `YOUR CODE HERE` sections in the function below to compute the gradients of the average dataset loss with respect to `w1`, `w2`, and `b` using the backpropagation rules for sigmoid + binary cross-entropy:\n",
    "\n",
    "*Hint: Review the formulas in the previous markdown cell.*\n",
    "\n",
    "After you complete this, run the next cell to compare your gradients to the finite-difference method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6013f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backprop_grads_dataset(X, y, w1, w2, b):\n",
    "    \"\"\"\n",
    "    Gradients of the AVERAGE dataset loss w.r.t. (w1, w2, b)\n",
    "    for sigmoid + BCE using the simplified rule:\n",
    "\n",
    "        dL/dz = p - y\n",
    "\n",
    "    where p = sigmoid(z) and z = w1*x1 + w2*x2 + b.\n",
    "\n",
    "    For one example:\n",
    "        dL/dw1 = (p - y) * x1\n",
    "        dL/dw2 = (p - y) * x2\n",
    "        dL/db  = (p - y)\n",
    "\n",
    "    X: list of data points, where each point is a list of 2 features [x1, x2]\n",
    "    y: list of true labels (0 or 1)\n",
    "    w1, w2: weights for the two features\n",
    "    b: bias term\n",
    "\n",
    "    Return: dL/dw1, dL/dw2, dL/db\n",
    "    \"\"\"\n",
    "    \n",
    "    grad_w1 = 0.0\n",
    "    grad_w2 = 0.0\n",
    "    grad_b  = 0.0\n",
    "\n",
    "    N = len(X)\n",
    "    \n",
    "    # Run forward once to get all the confidence values (p) for the dataset\n",
    "    p_list = forward(X, w1, w2, b)\n",
    "    \n",
    "    for j in range(N):\n",
    "        x1 = X[j][0]\n",
    "        x2 = X[j][1]\n",
    "        yj = y[j]\n",
    "        pj = p_list[j]\n",
    "\n",
    "        # Gradient of loss w.r.t. z (the linear score)\n",
    "        # For sigmoid + BCE: dL/dz = p - y\n",
    "        dL_dz = ... # YOUR CODE HERE\n",
    "\n",
    "        # Gradient of loss w.r.t. parameters (using the simplified backprop rule)\n",
    "        # Accumulate gradients over the dataset by summing contributions from each example\n",
    "        grad_w1 += ... # YOUR CODE HERE\n",
    "        grad_w2 += ... # YOUR CODE HERE\n",
    "        grad_b  += ... # YOUR CODE HERE\n",
    "\n",
    "    # Convert from SUM loss to AVERAGE loss\n",
    "    grad_w1 /= N\n",
    "    grad_w2 /= N\n",
    "    grad_b  /= N\n",
    "\n",
    "    return grad_w1, grad_w2, grad_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare finite-difference gradients vs backprop gradients at some test params\n",
    "w1_test, w2_test, b_test = 0.3, -0.2, 0.1\n",
    "\n",
    "fd = get_gradients(X_toy, y_toy, w1_test, w2_test, b_test)\n",
    "bp = get_backprop_grads_dataset(X_toy, y_toy, w1_test, w2_test, b_test)\n",
    "\n",
    "print(\"Finite diff:\", fd)\n",
    "print(\"Backprop:   \", bp)\n",
    "print(\"Abs diff:   \", (abs(fd[0]-bp[0]), abs(fd[1]-bp[1]), abs(fd[2]-bp[2])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62317f34",
   "metadata": {},
   "source": [
    "### Dataset loss\n",
    "\n",
    "Our training loop minimizes the **average loss over the entire dataset**:\n",
    "\n",
    "$$\n",
    "L_{\\text{avg}}(w_1, w_2, b) = \\frac{1}{N}\\sum_{j=1}^N L(p_j, y_j)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "p_j = \\sigma(z_j), \\qquad z_j = w_1 x_{1}^{(j)} + w_2 x_{2}^{(j)} + b\n",
    "$$\n",
    "\n",
    "So the gradients we want are:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L_{\\text{avg}}}{\\partial w_1},\\quad\n",
    "\\frac{\\partial L_{\\text{avg}}}{\\partial w_2},\\quad\n",
    "\\frac{\\partial L_{\\text{avg}}}{\\partial b}\n",
    "$$\n",
    "\n",
    "Backpropagation will compute the gradient contribution for each example and then we will **average** them.\n",
    "\n",
    "Note that, backprop still needs the forward predictions $p$. The speedup is that we no longer rerun the model once per parameter nudge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Training Loop\n",
    "\n",
    "# Initialize Parameters\n",
    "w1 = 0.0\n",
    "w2 = 0.0\n",
    "b  = 0.0\n",
    "\n",
    "# Initialize hyperparameters\n",
    "learning_rate = 0.1\n",
    "epochs = 500\n",
    "\n",
    "print(f\"Initial Loss: {get_avg_binary_cross_entropy(forward(X_toy, w1, w2, b), y_toy):.4f}\")\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    dw1, dw2, db = get_backprop_grads_dataset(X_toy, y_toy, w1, w2, b)\n",
    "    \n",
    "    w1 = w1 - learning_rate * dw1\n",
    "    w2 = w2 - learning_rate * dw2\n",
    "    b  = b  - learning_rate * db\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        # Check progress\n",
    "        curr_preds = forward(X_toy, w1, w2, b)\n",
    "        curr_loss = get_avg_binary_cross_entropy(curr_preds, y_toy)\n",
    "        print(f\"Iter {i}: w1={w1:.2f}, w2={w2:.2f}, b={b:.2f} | Loss={curr_loss:.4f}\")\n",
    "\n",
    "print(\"\\nFinal Result:\")\n",
    "print(\"Final loss:\", curr_loss)\n",
    "\n",
    "print(f\"w1: {w1:.4f}, w2: {w2:.4f}, b: {b:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyactivate)",
   "language": "python",
   "name": "pyactivate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
